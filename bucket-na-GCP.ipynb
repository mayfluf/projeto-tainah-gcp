
# - Projeto CLoud

Requisitos do projeto
Em seu projeto no Google Cloud Platform (GCP) em IAM e Administrador, conceder acesso ao e-mail: douglas.ribeiro@soulcode.com;
- Criar um bucket no Google Cloud Storage;
- Criar uma pasta chamada dados-brutos dentre desse bucket;
- Criar uma pasta dados-tratados;
- Baixar um arquivo específico do google planilhas no formato em formato csv na máquina local (link para o arquivo):
https://docs.google.com/spreadsheets/d/1oTKRjvTyEcScUvWqi-Arcp8AqXNeKK2iU5D4rW25cdo/edit?usp=sharing
- Subir o arquivo da sua máquina para a pasta dados brutos e conceder acesso público a este arquivo;
- Utilizar o link de acesso público desse arquivo no google colab e fazer a leitura do arquivo com a biblioteca pandas,
transformar cada coluna do arquivo em uma lista Python;
- Fazer os tratamentos utilizando os métodos e funções de listas aprendidos em aula;
- Devolver as listas tratadas ao Data Frame Pandas;
- Salvar o Data Frame e enviá-lo automaticamente para a pasta dados-tratados do Bucket na GCP.

Obs.: Registos que não tiverem todas as informações deverão ser excluídos e isso deverá ser feito utilizando métodos e funções de listas no colab.

'''

import pandas as pd
     

tabela = pd.read_csv('https://storage.googleapis.com/cloud_projeto/dados-brutos/dados_inconsistentes%20-%20dados_inconsistentes.csv')
display (type(tabela))
     

# Convertendo o DataFrame em uma lista de dicionários
func = tabela.to_dict(orient='records')

# Criando listas vazias para os dados
lista_nomes = []
lista_idade = []
lista_salario = []
lista_cargo = []
lista_departamento = []

# Passando os dados de cada dicionário para listas
for item in func:
    lista_nomes.append(item['nome'])
    lista_idade.append(item['idade'])
    lista_salario.append(item['salário'])
    lista_cargo.append(item['cargo'])
    lista_departamento.append(item['departamento'])

# Convertendo float para str
for i in range(len(lista_idade)):
    lista_idade[i] = str(lista_idade[i])

for i in range(len(lista_salario)):
    lista_salario[i] = str(lista_salario[i])

for i in range(len(lista_departamento)):
    lista_departamento[i] = str(lista_departamento[i])

for i in range(len(lista_cargo)):
    lista_cargo[i] = str(lista_cargo[i])

# Criando lista de dicionários
lista_dicionarios = []
for i in range(len(lista_nomes)):
    # Verificando se não há valores em branco ou NaN
    if (lista_nomes[i] != '' and lista_nomes[i] != 'nan' and
        lista_idade[i] != '' and lista_idade[i] != 'nan' and
        lista_salario[i] != '' and lista_salario[i] != 'nan' and
        lista_cargo[i] != '' and lista_cargo[i] != 'nan' and
        lista_departamento[i] != '' and lista_departamento[i] != 'nan'):


        # Adicionando ao dicionário

      lista_dicionarios.append({
        'nome': lista_nomes[i],
        'idade': int(float(lista_idade[i])),
        'salario': float(lista_salario[i]),
        'cargo': lista_cargo[i],
        'departamento': lista_departamento[i]
        })


# tranformei em dataframe novamente
df_tratado = pd.DataFrame(lista_dicionarios)
display(df_tratado) #Pra ver o data frame


     

from google.colab import auth
auth.authenticate_user()
project_id = 'fifth-brook-440013-a0'#cria variavel que recebe o nome do projeto
!gcloud config set project {project_id} #aponta para o projeto guardado na variavel
from google.cloud import storage #cria variavel cliente
client = storage.Client() #cria variavel com nome da bucket
bucket_name = 'cloud_projeto' #aponta para a variavel bucket
bucket = client.bucket(bucket_name)  #Acessa um bucket específico no Google Cloud Storage usando o cliente definido.
df_tratado.to_csv('dadostratados.csv',index=False) #salva um DataFrame como um arquivo CSV chamado dadostratados.csv, excluindo o índice.
from google.cloud import storage #importa a biblioteca storage do Google Cloud para interagir com o Cloud Storage.
destination_blob_name = 'dados-tratados/tratados.csv' #criando caminho do destino (nomedapasta/nomedoarquivo)
source_file_name = 'dadostratados.csv' #caminho arquivo fonte
blob = bucket.blob(destination_blob_name) #mando para o destino
blob.upload_from_filename(source_file_name) #faz upload
     
Updated property [core/project].
